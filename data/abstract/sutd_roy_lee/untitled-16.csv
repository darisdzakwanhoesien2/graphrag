DOI,Title,Authors,Journal,Year,Abstract,LitmapsId,Cited By,References,PubMedId,Tags
10.1145/3041021.3054223,Deep Learning for Hate Speech Detection in Tweets,"Pinkesh Badjatiya, Shashank Gupta, Manish Gupta, Vasudeva Varma",arXiv: Computation and Language,2017,"Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ~18 F1 points.",65864534,1326,7,,SUTD - Roy Lee Task 1 Part 1
10.3390/s19214654,Detecting and Monitoring Hate Speech in Twitter,"Juan Carlos Pereira-Kohatsu, L. Sánchez, F. Liberatore, M. Camacho-Collados",Sensors,2019,"Social Media are sensors in the real world that can be used to measure the pulse of societies. However, the massive and unfiltered feed of messages posted in social media is a phenomenon that nowadays raises social alarms, especially when these messages contain hate speech targeted to a specific individual or group. In this context, governments and non-governmental organizations (NGOs) are concerned about the possible negative impact that these messages can have on individuals or on the society. In this paper, we present HaterNet, an intelligent system currently being used by the Spanish National Office Against Hate Crimes of the Spanish State Secretariat for Security that identifies and monitors the evolution of hate speech in Twitter. The contributions of this research are many-fold: (1) It introduces the first intelligent system that monitors and visualizes, using social network analysis techniques, hate speech in Social Media. (2) It introduces a novel public dataset on hate speech in Spanish consisting of 6000 expert-labeled tweets. (3) It compares several classification approaches based on different document representation strategies and text classification models. (4) The best approach consists of a combination of a LTSM+MLP neural network that takes as input the tweet’s word, emoji, and expression tokens’ embeddings enriched by the tf-idf, and obtains an area under the curve (AUC) of 0.828 on our dataset, outperforming previous methods presented in the literature.",261200311,200,91,,SUTD - Roy Lee Task 1 Part 1
10.1016/j.ipm.2019.102087,Vulnerable community identification using hate speech detection on social media,"Zewdie Mossie, Jenq-Haur Wang",Information Processing and Management,2020,(missing abstract),217073072,167,49,,SUTD - Roy Lee Task 1 Part 1
10.1145/3377323,A Multilingual Evaluation for Online Hate Speech Detection,"Michele Corazza, Stefano Menini, Elena Cabrio, Sara Tonelli, S. Villata",ACM Trans. Internet Techn.,2020,"The increasing popularity of social media platforms such as Twitter and Facebook has led to a rise in the presence of hate and aggressive speech on these platforms. Despite the number of approaches recently proposed in the Natural Language Processing research area for detecting these forms of abusive language, the issue of identifying hate speech at scale is still an unsolved problem. In this article, we propose a robust neural architecture that is shown to perform in a satisfactory way across different languages; namely, English, Italian, and German. We address an extensive analysis of the obtained experimental results over the three languages to gain a better understanding of the contribution of the different components employed in the system, both from the architecture point of view (i.e., Long Short Term Memory, Gated Recurrent Unit, and bidirectional Long Short Term Memory) and from the feature selection point of view (i.e., ngrams, social network–specific features, emotion lexica, emojis, word embeddings). To address such in-depth analysis, we use three freely available datasets for hate speech detection on social media in English, Italian, and German.",73679899,158,70,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1007/s00607-019-00745-0,Automatic hate speech detection using killer natural language processing optimizing ensemble deep learning approach,"Zafer Al-makhadmeh, A. Tolba",Computing,2020,"Over the last decade, the increased use of social media has led to an increase in hateful activities in social networks. Hate speech is one of the most dangerous of these activities, so users have to protect themselves from these activities from YouTube, Facebook, Twitter etc. This paper introduces a method for using a hybrid of natural language processing and with machine learning technique to predict hate speech from social media websites. After hate speech is collected, steaming, token splitting, character removal and inflection elimination is performed before performing hate speech recognition process. After that collected data is examined using a killer natural language processing optimization ensemble deep learning approach (KNLPEDNN). This method detects hate speech on social media websites using an effective learning process that classifies the text into neutral, offensive and hate language. The performance of the system is then evaluated using overall accuracy, f-score, precision and recall metrics. The system attained minimum deviations mean square error − 0.019, Cross Entropy Loss − 0.015 and Logarithmic loss L-0.0238 and 98.71% accuracy.",56932236,121,48,,SUTD - Roy Lee Task 1 Part 1
10.1109/access.2021.3089515,Advances in Machine Learning Algorithms for Hate Speech Detection in Social Media: A Review,"Nanlir Sallau Mullah, Wan Mohd Nazmee Wan Zainon",IEEE Access,2021,"The aim of this paper is to review machine learning (ML) algorithms and techniques for hate speech detection in social media (SM). Hate speech problem is normally model as a text classification task. In this study, we examined the basic baseline components of hate speech classification using ML algorithms. There are five basic baseline components – data collection and exploration, feature extraction, dimensionality reduction, classifier selection and training, and model evaluation, were reviewed. There have been improvements in ML algorithms that were employed for hate speech detection over time. New datasets and different performance metrics have been proposed in the literature. To keep the researchers informed regarding these trends in the automatic detection of hate speech, it calls for a comprehensive and an updated state-of-the-art. The contributions of this study are three-fold. First to equip the readers with the necessary information on the critical steps involved in hate speech detection using ML algorithms. Secondly, the weaknesses and strengths of each method is critically evaluated to guide researchers in the algorithm choice dilemma. Lastly, some research gaps and open challenges were identified. The different variants of ML techniques were reviewed which include classical ML, ensemble approach and deep learning methods. Researchers and professionals alike will benefit immensely from this study.",151072440,118,87,,SUTD - Roy Lee Task 1 Part 1
10.1016/j.eswa.2020.113725,Detecting and visualizing hate speech in social media: A cyber Watchdog for surveillance,"Sandip Modha, Prasenjit Majumder, Thomas Mandl, Chintak Mandalia",Expert systems with applications,2020,(missing abstract),43610152,102,27,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
(missing DOI),Improving Hate Speech Detection with Deep Learning Ensembles,"Steven Zimmerman, Udo Kruschwitz, C. Fox",International Conference on Language Resources and Evaluation,2018,"Hate speech has become a major issue that is currently a hot topic in the domain of social media. Simultaneously, current proposed methods to address the issue raise concerns about censorship. Broadly speaking, our research focus is the area human rights, including the development of new methods to identify and better address discrimination while protecting freedom of expression. As neural network approaches are becoming state of the art for text classification problems, an ensemble method is adapted for usage with neural networks and is presented to better classify hate speech. Our method utilizes a publicly available embedding model, which is tested against a hate speech corpus from Twitter. To confirm robustness of our results, we additionally test against a popular sentiment dataset. Given our goal, we are pleased that our method has a nearly 5 point improvement in F-measure when compared to original work on a publicly available hate speech evaluation dataset. We also note difficulties encountered with reproducibility of deep learning methods and comparison of findings from other work. Based on our experience, more details are needed in published work reliant on deep learning methods, with additional evaluation information a consideration too. This information is provided to foster discussion within the research community for future work.",276314529,102,5,,SUTD - Roy Lee Task 1 Part 1
10.1613/jair.1.12590,Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective,"Svetlana Kiritchenko, Isar Nejadgholi, Kathleen C. Fraser",Journal of Artificial Intelligence Research,2021,"The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this technology can cause unintended harms, such as the silencing of under-represented groups. We review a large body of NLP research on automatic abuse detection with a new focus on ethical challenges, organized around eight established ethical principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. In many cases, these principles relate not only to situational ethical codes, which may be context-dependent, but are in fact connected to universal human rights, such as the right to privacy, freedom from discrimination, and freedom of expression. We highlight the need to examine the broad social impacts of this technology, and to bring ethical and human rights considerations to every stage of the application life-cycle, from task formulation and dataset design, to model training and evaluation, to application deployment. Guided by these principles, we identify several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse, including ‘nudging’, ‘quarantining’, value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.evaluation, to application deployment. Guided by these principles, we identify several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse, including 'nudging', 'quarantining', value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.",261177854,97,110,,SUTD - Roy Lee Task 1 Part 1
(missing DOI),Tackling Online Abuse: A Survey of Automated Abuse Detection Methods,"Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova",arXiv: Computation and Language,2019,"Abuse on the Internet represents an important societal problem of our time. Millions of Internet users face harassment, racism, personal attacks, and other types of abuse on online platforms. The psychological effects of such abuse on individuals can be profound and lasting. Consequently, over the past few years, there has been a substantial research effort towards automated abuse detection in the field of natural language processing (NLP). In this paper, we present a comprehensive survey of the methods that have been proposed to date, thus providing a platform for further development of this area. We describe the existing datasets and review the computational approaches to abuse detection, analyzing their strengths and limitations. We discuss the main trends that emerge, highlight the challenges that remain, outline possible solutions, and propose guidelines for ethics and explainability",261368873,86,79,,SUTD - Roy Lee Task 1 Part 1
10.1109/access.2020.2968173,Evaluating Machine Learning Techniques for Detecting Offensive and Hate Speech in South African Tweets,"O. Oriola, E. Kotzé",IEEE Access,2020,"In recent times, South Africa has been witnessing insurgence of offensive and hate speech along racial and ethnic dispositions on Twitter. Popular among the South African languages used is English. Although, machine learning has been successfully used to detect offensive and hate speech in several English contexts, the distinctiveness of South African tweets and the similarities among offensive, hate and free speeches require domain-specific English corpus and techniques to detect the offensive and hate speech. Thus, we developed an English corpus from South African tweets and evaluated different machine learning techniques to detect offensive and hate speech. Character n-gram, word n-gram, negative sentiment, syntactic-based features and their hybrid were extracted and analyzed using hyper-parameter optimization, ensemble and multi-tier meta-learning models of support vector machine, logistic regression, random forest, gradient boosting algorithms. The results showed that optimized support vector machine with character n-gram performed best in detection of hate speech with true positive rate of 0.894, while optimized gradient boosting with word n-gram performed best in detection of hate speech with true positive rate of 0.867. However, their performances in detection of other threatening classes were poor. Multi-tier meta-learning models achieved the most consistent and balanced classification performance with true positive rates of 0.858 and 0.887 for hate speech and offensive speech, respectively as well as true positive rate of 0.646 for free speech and overall accuracy of 0.671. The error analysis showed that multi-tier meta-learning model could reduce the misclassification error rate of the optimized models by 34.26%.",152541904,84,31,,SUTD - Roy Lee Task 1 Part 1
10.20944/preprints202011.0646.v1,Online Multilingual Hate Speech Detection: Experimenting with Hindi and English Social Media,"Neeraj Vashistha, A. Zubiaga",Inf.,2020,"The last two decades have seen an exponential increase in the use of the Internet and social media, which has changed basic human interaction. This has led to many positive outcomes. At the same time, it has brought risks and harms. The volume of harmful content online, such as hate speech, is not manageable by humans. The interest in the academic community to investigate automated means for hate speech detection has increased. In this study, we analyse six publicly available datasets by combining them into a single homogeneous dataset. Having classified them into three classes, abusive, hateful or neither, we create a baseline model and improve model performance scores using various optimisation techniques. After attaining a competitive performance score, we create a tool that identifies and scores a page with an effective metric in near-real-time and uses the same feedback to re-train our model. We prove the competitive performance of our multilingual model in two languages, English and Hindi. This leads to comparable or superior performance to most monolingual models.",145136131,84,35,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/access.2020.3009244,Deep Learning Based Fusion Approach for Hate Speech Detection,"Yanling Zhou, Yanyan Yang, Han Liu, Xiufeng Liu, N. Savage",IEEE Access,2020,"In recent years, the increasing prevalence of hate speech in social media has been considered as a serious problem worldwide. Many governments and organizations have made significant investment in hate speech detection techniques, which have also attracted the attention of the scientific community. Although plenty of literature focusing on this issue is available, it remains difficult to assess the performances of each proposed method, as each has its own advantages and disadvantages. A general way to improve the overall results of classification by fusing the various classifiers results is a meaningful attempt. We first focus on several famous machine learning methods for text classification such as Embeddings from Language Models (ELMo), Bidirectional Encoder Representation from Transformers (BERT) and Convolutional Neural Network (CNN), and apply these methods to the data sets of the SemEval 2019 Task 5. We then adopt some fusion strategies to combine the classifiers to improve the overall classification performance. The results show that the accuracy and F1-score of the classification are significantly improved.",220537045,77,27,,SUTD - Roy Lee Task 1 Part 1
10.1007/978-3-030-44289-7_24,Comparative Performance of Machine Learning and Deep Learning Algorithms for Arabic Hate Speech Detection in OSNs,"Ahmed Omar, Tarek M. Mahmoud, Tarek Abd-El-Hafeez",International Conferences on Artificial Intelligence and Computer Vision,2020,"Nowadays, Online Social Networks (OSNs) are the most popular and interactive media that used to express feelings, communicate and share information between people. However, along with useful and interesting content, sometimes unsuitable or abusive content can be published on these networks, such as hate speech and insults. Hate speech includes any type of online abuse concepts like cyberbullying, discrimination, abusive language, profanity, flaming, toxicity, and harassment. Most of the Hate speech detection attempts have concentrated on the English text, while work on the Arabic text is sparse. In this paper, we constructed a standard Arabic dataset that can be used for hate speech and abuse detection. In contrast to most previous work the datasets were collected from one platform, the proposed dataset is collected from more social network platforms (Facebook, Twitter, Instagram, and YouTube). To validate the effectiveness of the proposed datasets twelve machine learning algorithms and two deep learning architecture were used. Recurrent Neural Network (RNN) outperformed other classifiers with an accuracy of 98.7%.",46931746,76,20,,SUTD - Roy Lee Task 1 Part 1
10.1007/s00530-023-01051-8,A literature survey on multimodal and multilingual automatic hate speech identification,"Anusha Chhabra, D. Vishwakarma",Multimedia Systems,2023,(missing abstract),254682433,75,170,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1016/j.aej.2023.08.038,A survey on hate speech detection and sentiment analysis using machine learning and deep learning models,"Malliga Subramanian, Veerappampalayam Easwaramoorthy Sathiskumar, G. Deepalakshmi, Jaehyuk Cho, G. Manikandan",Alexandria Engineering Journal,2023,(missing abstract),265139554,71,90,,SUTD - Roy Lee Task 1 Part 1
10.3390/a15080291,Social Media Hate Speech Detection Using Explainable Artificial Intelligence (XAI),"Harshkumar Mehta, K. Passi",Algorithms,2022,"Explainable artificial intelligence (XAI) characteristics have flexible and multifaceted potential in hate speech detection by deep learning models. Interpreting and explaining decisions made by complex artificial intelligence (AI) models to understand the decision-making process of these model were the aims of this research. As a part of this research study, two datasets were taken to demonstrate hate speech detection using XAI. Data preprocessing was performed to clean data of any inconsistencies, clean the text of the tweets, tokenize and lemmatize the text, etc. Categorical variables were also simplified in order to generate a clean dataset for training purposes. Exploratory data analysis was performed on the datasets to uncover various patterns and insights. Various pre-existing models were applied to the Google Jigsaw dataset such as decision trees, k-nearest neighbors, multinomial naïve Bayes, random forest, logistic regression, and long short-term memory (LSTM), among which LSTM achieved an accuracy of 97.6%. Explainable methods such as LIME (local interpretable model—agnostic explanations) were applied to the HateXplain dataset. Variants of BERT (bidirectional encoder representations from transformers) model such as BERT + ANN (artificial neural network) with an accuracy of 93.55% and BERT + MLP (multilayer perceptron) with an accuracy of 93.67% were created to achieve a good performance in terms of explainability using the ERASER (evaluating rationales and simple English reasoning) benchmark.",244001420,67,39,,SUTD - Roy Lee Task 1 Part 1
10.1007/s41060-024-00650-6,Deep learning for hate speech detection: a comparative study,"Jitendra Singh Malik, Hezhe Qiao, Guansong Pang, Anton van den Hengel",International Journal of Data Science and Analytics,2024,"Automated hate speech detection is an important tool in combating the spread of hate speech, particularly in social media. Numerous methods have been developed for the task, including a recent proliferation of deep-learning based approaches. A variety of datasets have also been developed, exemplifying various manifestations of the hate-speech detection problem. We present here a largescale empirical comparison of deep and shallow hate-speech detection methods, mediated through the three most commonly used datasets. Our goal is to illuminate progress in the area, and identify strengths and weaknesses in the current state-of-the-art. We particularly focus our analysis on measures of practical performance, including detection accuracy, computational efficiency, capability in using pre-trained models, and domain generalization. In doing so we aim to provide guidance as to the use of hate-speech detection in practice, quantify the state-of-the-art, and identify future research directions.",279883083,63,86,,SUTD - Roy Lee Task 1 Part 1
10.48550/arxiv.2202.09517,Deep Learning for Hate Speech Detection: A Comparative Study,"Malik, Jitendra Singh, Pang, Guansong, Hengel, Anton van den",International Journal of Data Science and Analysis,2022,"Automated hate speech detection is an important tool in combating the spread of hate speech, particularly in social media. Numerous methods have been developed for the task, including a recent proliferation of deep-learning based approaches. A variety of datasets have also been developed, exemplifying various manifestations of the hate-speech detection problem. We present here a largescale empirical comparison of deep and shallow hate-speech detection methods, mediated through the three most commonly used datasets. Our goal is to illuminate progress in the area, and identify strengths and weaknesses in the current state-of-the-art. We particularly focus our analysis on measures of practical performance, including detection accuracy, computational efficiency, capability in using pre-trained models, and domain generalization. In doing so we aim to provide guidance as to the use of hate-speech detection in practice, quantify the state-of-the-art, and identify future research directions.",253725605,61,73,,SUTD - Roy Lee Task 1 Part 1
10.1002/wics.1648,"Hate speech detection in social media: Techniques, recent trends, and future challenges","Anchal Rawat, Santosh Kumar, Surender Singh Samant",WIREs Computational Statistics,2024,"The realm of Natural Language Processing and Text Mining has seen a surge in interest from researchers in hate speech detection, leading to an increase in related studies. This analysis aims to create a valuable resource by summarizing the methods and strategies used to combat hate speech in social media. We perform a detailed review to achieve a deep knowledge of the hate speech detection landscape from 2018 to 2023, revealing global incidents of hate speech in 2022–2023. Sixty‐six relevant articles were selected for this review. Existing studies were analyzed and categorized into five method categories: Machine Learning, Deep Learning, Ensemble models, Graph Neural Networks, and Graph Convolutional Networks. These advancements can aid social networking services in identifying hate messages before being posted, reducing the risk of harassment. The review also covers available hate speech datasets and highlights research challenges, but it is clear that a definitive solution to this problem is yet to be found. Future research directions are recommended to address the ongoing challenges in Hate Speech Detection.",270523600,52,127,,SUTD - Roy Lee Task 1 Part 1
10.1145/3371276,MANDOLA: A Big-Data Processing and Visualization Platform for Monitoring and Detecting Online Hate Speech,"Demetris Paschalides, Dimosthenis Stephanidis, Andreas G. Andreou, Kalia Orphanou, G. Pallis, M. Dikaiakos, E. Markatos",ACM Trans. Internet Techn.,2020,"In recent years, the increasing propagation of hate speech in online social networks and the need for effective counter-measures have drawn significant investment from social network companies and researchers. This has resulted in the development of many web platforms and mobile applications for reporting and monitoring online hate speech incidents. In this article, we present MANDOLA, a big-data processing system that monitors, detects, visualizes, and reports the spread and penetration of online hate-related speech using big-data approaches. MANDOLA consists of six individual components that intercommunicate to consume, process, store, and visualize statistical information regarding hate speech spread online. We also present a novel ensemble-based classification algorithm for hate speech detection that can significantly improve the performance of MANDOLA’s ability to detect hate speech. To present the functionality and usability of our system, we present a use case scenario of real-life event annotation and data correlation. As shown from the performance of the individual modules, as well as the usability and functionality of the whole system, MANDOLA is a powerful system for reporting and monitoring online hate speech.",218752335,48,78,,"SUTD - Roy Lee Task 1 Part 1, SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/mic.2020.3037034,HateClassify: A Service Framework for Hate Speech Identification on Social Media,"M. U. S. Khan, Assad Abbas, Attiqa Rehman, R. Nawaz",IEEE Internet Computing,2021,"It is indeed a challenge for the existing machine learning approaches to segregate the hateful content from the one that is merely offensive. One prevalent reason for low accuracy of hate detection with the current methodologies is that these techniques treat hate classification as a multiclass problem. In this article, we present the hate identification on the social media as a multilabel problem. To this end, we propose a CNN-based service framework called “HateClassify” for labeling the social media contents as the hate speech, offensive, or nonoffensive. Results demonstrate that the multiclass classification accuracy for the CNN-based approaches particularly sequential CNN (SCNN) is competitive and even higher than certain state-of-the-art classifiers. Moreover, in the multilabel classification problem, sufficiently high performance is exhibited by the SCNN among other CNN-based techniques. The results have shown that using multilabel classification instead of multiclass classification, hate speech detection is increased up to 20%.",167910864,40,19,,SUTD - Roy Lee Task 1 Part 1
10.1016/j.eswa.2023.121115,Improving hate speech detection using Cross-Lingual Learning,"Anderson Almeida Firmino, Cláudio de Souza Baptista, Anselmo Cardoso de Paiva",Expert systems with applications,2023,(missing abstract),264137968,37,10,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.14569/ijacsa.2023.0140542,Hate Speech Detection in Social Networks using Machine Learning and Deep Learning Methods,"A. Toktarova, Dariga Syrlybay, B.B. Myrzakhmetova, G. Anuarbekova, Gulbarshin Rakhimbayeva, Balkiya Zhylanbaeva, Nabat Suieuova, Mukhtar Kerimbekov",International Journal of Advanced Computer Science and Applications,2023,"—Hate speech on social media platforms like Twitter is a growing concern that poses challenges to maintaining a healthy online environment and fostering constructive communication. Effective detection and monitoring of hate speech are crucial for mitigating its adverse impact on individuals and communities. In this paper, we propose a comprehensive approach for hate speech detection on Twitter using both traditional machine learning and deep learning techniques. Our research encompasses a thorough comparison of these techniques to determine their effectiveness in identifying hate speech on Twitter. We construct a robust dataset, gathered from diverse sources and annotated by experts, to ensure the reliability of our models. The dataset consists of tweets labeled as hate speech, offensive language, or neutral, providing a more nuanced representation of online discourse. We evaluate the performance of LSTM, BiLSTM, and CNN models against traditional shallow learning methods to establish a baseline for comparison. Our findings reveal that deep learning techniques outperform shallow learning methods, with BiLSTM emerging as the most accurate model for hate speech detection. The BiLSTM model demonstrates improved sensitivity to context, semantic nuances, and sequential patterns in tweets, making it adept at capturing the intricate nature of hate speech. Furthermore, we explore the integration of word embeddings, such as Word2Vec and GloVe, to enhance the performance of our models. The incorporation of these embeddings significantly improves the models' ability to discern between hate speech and other forms of online communication. This paper presents a comprehensive analysis of various machine learning methods for hate speech detection on Twitter, ultimately demonstrating the superiority of deep learning techniques, particularly BiLSTM, in addressing this critical issue. Our findings pave the way for further research into advanced methods of tackling hate speech and facilitating healthier online interactions.",262355943,36,48,,SUTD - Roy Lee Task 1 Part 1
10.3390/fi13030080,A Web Interface for Analyzing Hate Speech,"Lazaros Vrysis, N. Vryzas, Rigas Kotsakis, Theodora Saridou, María Matsiola, A. Veglis, Carlos Arcila Calderón, Charalampos A. Dimoulas",Future Internet,2021,"Social media services make it possible for an increasing number of people to express their opinion publicly. In this context, large amounts of hateful comments are published daily. The PHARM project aims at monitoring and modeling hate speech against refugees and migrants in Greece, Italy, and Spain. In this direction, a web interface for the creation and the query of a multi-source database containing hate speech-related content is implemented and evaluated. The selected sources include Twitter, YouTube, and Facebook comments and posts, as well as comments and articles from a selected list of websites. The interface allows users to search in the existing database, scrape social media using keywords, annotate records through a dedicated platform and contribute new content to the database. Furthermore, the functionality for hate speech detection and sentiment analysis of texts is provided, making use of novel methods and machine learning models. The interface can be accessed online with a graphical user interface compatible with modern internet browsers. For the evaluation of the interface, a multifactor questionnaire was formulated, targeting to record the users’ opinions about the web interface and the corresponding functionality.",222355136,32,70,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1016/j.compeleceng.2024.109153,Towards safer online communities: Deep learning and explainable AI for hate speech detection and classification,"Hareem Kibriya, A. Siddiqa, Wazir Zada Khan, Muhammad Khurram Khan",Computers & electrical engineering,2024,(missing abstract),273930073,31,12,,SUTD - Roy Lee Task 1 Part 1
10.3390/app11188575,Automatic Hate Speech Detection in English-Odia Code Mixed Social Media Data Using Machine Learning Techniques,"Sudhir Kumar Mohapatra, S. Prasad, D. K. Bebarta, T. K. Das, Kathiravan Srinivasan, Yuh-Chung Hu",Applied Sciences,2021,"Hate speech on social media may spread quickly through online users and subsequently, may even escalate into local vile violence and heinous crimes. This paper proposes a hate speech detection model by means of machine learning and text mining feature extraction techniques. In this study, the authors collected the hate speech of English-Odia code mixed data from a Facebook public page and manually organized them into three classes. In order to build binary and ternary datasets, the data are further converted into binary classes. The modeling of hate speech employs the combination of a machine learning algorithm and features extraction. Support vector machine (SVM), naïve Bayes (NB) and random forest (RF) models were trained using the whole dataset, with the extracted feature based on word unigram, bigram, trigram, combined n-grams, term frequency-inverse document frequency (TF-IDF), combined n-grams weighted by TF-IDF and word2vec for both the datasets. Using the two datasets, we developed two kinds of models with each feature—binary models and ternary models. The models based on SVM with word2vec achieved better performance than the NB and RF models for both the binary and ternary categories. The result reveals that the ternary models achieved less confusion between hate and non-hate speech than the binary models.",55438137,30,45,,SUTD - Roy Lee Task 1 Part 1
10.1109/aciiw.2019.8925079,Leveraging Hate Speech Detection to Investigate Immigration-related Phenomena in Italy,"Komal Florio, Valerio Basile, Mirko Lai, V. Patti",2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),2019,"The presence and integration of immigrants is one of the most controversial issues in our society, and given current worldwide political instabilities, it will likely become ever more prominent in the cultural and political debate. Social media play an increasingly important role in how citizens debate opinions and react to local and global events. However, several studies point out the danger of social media as a breeding ground for online hate speech (or cyberhate). We propose a novel approach to the exploratory analysis of social phenomena based on the integration of automatic detection of cyberhate against immigrants with offline indicators. We gathered data from the Italian Twittersphere and from the main supplier of official statistical data in Italy (ISTAT). We developed a supervised classification model for hate speech detection, trained on a corpus of Italian tweets manually annotated for hate speech against immigrants, and use it to automatically annotate a large sample of geo-tagged tweets over a span of six years. We crossed this data with the ISTAT data, exploring three macro-indicators related to employment, education and crime. We found correlations suggesting an interplay between economical and cultural factors and the expression of hate online.",39028821,29,26,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1145/3534678.3539161,Proactively Reducing the Hate Intensity of Online Posts via Hate Speech Normalization,"Sarah Masud, Manjot Bedi, Mohammad Aflah Khan, Md. Shad Akhtar, Tanmoy Chakraborty",Knowledge Discovery and Data Mining,2022,"Curbing online hate speech has become the need of the hour; however, a blanket ban on such activities is infeasible for several geopolitical and cultural reasons. To reduce the severity of the problem, in this paper, we introduce a novel task, hate speech normalization, that aims to weaken the intensity of hatred exhibited by an online post. The intention of hate speech normalization is not to support hate but instead to provide the users with a stepping stone towards non-hate while giving online platforms more time to monitor any improvement in the user's behavior. To this end, we manually curated a parallel corpus - hate texts and their normalized counterparts (a normalized text is less hateful and more benign). We introduce NACL, a simple yet efficient hate speech normalization model that operates in three stages - first, it measures the hate intensity of the original sample; second, it identifies the hate span(s) within it; and finally, it reduces hate intensity by paraphrasing the hate spans. We perform extensive experiments to measure the efficacy of NACL via three-way evaluation (intrinsic, extrinsic, and human-study). We observe that NACL outperforms six baselines - NACL yields a score of 0.1365 RMSE for the intensity prediction, 0.622 F1-score in the span identification, and 82.27 BLEU and 80.05 perplexity for the normalized text generation. We further show the generalizability of NACL across other platforms (Reddit, Facebook, Gab). An interactive prototype of NACL was put together for the user study. Further, the tool is being deployed in a real-world setting at Wipro AI as a part of its mission to tackle harmful content on online platforms.",238850537,28,47,,SUTD - Roy Lee Task 1 Part 1
10.1109/access.2024.3367281,Enhancing Hate Speech Detection in the Digital Age: A Novel Model Fusion Approach Leveraging a Comprehensive Dataset,"Waqas Sharif, Saima Abdullah, Saman Iftikhar, Daniah Al-Madani, Shahzad Mumtaz",IEEE Access,2024,"In the era of digital communication, social media platforms have experienced exponential growth, becoming primary channels for information exchange. However, this surge has also amplified the rapid spread of hate speech, prompting extensive research efforts for effective mitigation. These efforts have prominently featured advanced natural language processing techniques, particularly emphasizing deep learning methods that have shown promising outcomes. This article presents a novel approach to address this pressing issue, combining a comprehensive dataset of 18 sources. It includes 0.45 million comments sourced from various digital platforms spanning different time frames. There were two models utilized to address the diversity in the data and leverage distinct strengths found within deep learning frameworks: CNN and BiLSTM with an attention mechanism. These models were tailored to handle specific subsets of the data, allowing for a more targeted approach. The unique outputs from both models were then fused into a unified model. This methodology outperformed recent models, showcasing enhanced generalization capabilities even when tested on the largest and most diverse dataset. Our model achieved an impressive accuracy of 89%, while maintaining a high precision of 0.88 and recall of 0.91.",269967534,27,58,,SUTD - Roy Lee Task 1 Part 1
10.1007/s42001-024-00248-9,A survey of explainable AI techniques for detection of fake news and hate speech on social media platforms,"Vaishali U. Gongane, M. Munot, A. Anuse",Journal of Computational Social Science,2024,(missing abstract),270303385,26,64,,SUTD - Roy Lee Task 1 Part 1
10.1108/dta-01-2019-0007,Combating the challenges of social media hate speech in a polarized society: A Twitter ego lexalytics approach,"Collins N. Udanor, Chinatu C. Anyanwu",Drug Testing and Analysis,2019,"Hate speech in recent times has become a troubling development. It has different meanings to different people in different cultures. The anonymity and ubiquity of the social media provides a breeding ground for hate speech and makes combating it seems like a lost battle. However, what may constitute a hate speech in a cultural or religious neutral society may not be perceived as such in a polarized multi-cultural and multi-religious society like Nigeria. Defining hate speech, therefore, may be contextual. Hate speech in Nigeria may be perceived along ethnic, religious and political boundaries. The purpose of this paper is to check for the presence of hate speech in social media platforms like Twitter, and to what degree is hate speech permissible, if available? It also intends to find out what monitoring mechanisms the social media platforms like Facebook and Twitter have put in place to combat hate speech. Lexalytics is a term coined by the authors from the words lexical analytics for the purpose of opinion mining unstructured texts like tweets.,This research developed a Python software called polarized opinions sentiment analyzer (POSA), adopting an ego social network analytics technique in which an individual’s behavior is mined and described. POSA uses a customized Python N-Gram dictionary of local context-based terms that may be considered as hate terms. It then applied the Twitter API to stream tweets from popular and trending Nigerian Twitter handles in politics, ethnicity, religion, social activism, racism, etc., and filtered the tweets against the custom dictionary using unsupervised classification of the texts as either positive or negative sentiments. The outcome is visualized using tables, pie charts and word clouds. A similar implementation was also carried out using R-Studio codes and both results are compared and a t-test was applied to determine if there was a significant difference in the results. The research methodology can be classified as both qualitative and quantitative. Qualitative in terms of data classification, and quantitative in terms of being able to identify the results as either negative or positive from the computation of text to vector.,The findings from two sets of experiments on POSA and R are as follows: in the first experiment, the POSA software found that the Twitter handles analyzed contained between 33 and 55 percent hate contents, while the R results show hate contents ranging from 38 to 62 percent. Performing a t-test on both positive and negative scores for both POSA and R-studio, results reveal p-values of 0.389 and 0.289, respectively, on an α value of 0.05, implying that there is no significant difference in the results from POSA and R. During the second experiment performed on 11 local handles with 1,207 tweets, the authors deduce as follows: that the percentage of hate contents classified by POSA is 40 percent, while the percentage of hate contents classified by R is 51 percent. That the accuracy of hate speech classification predicted by POSA is 87 percent, while free speech is 86 percent. And the accuracy of hate speech classification predicted by R is 65 percent, while free speech is 74 percent. This study reveals that neither Twitter nor Facebook has an automated monitoring system for hate speech, and no benchmark is set to decide the level of hate contents allowed in a text. The monitoring is rather done by humans whose assessment is usually subjective and sometimes inconsistent.,This study establishes the fact that hate speech is on the increase on social media. It also shows that hate mongers can actually be pinned down, with the contents of their messages. The POSA system can be used as a plug-in by Twitter to detect and stop hate speech on its platform. The study was limited to public Twitter handles only. N-grams are effective features for word-sense disambiguation, but when using N-grams, the feature vector could take on enormous proportions and in turn increasing sparsity of the feature vectors.,The findings of this study show that if urgent measures are not taken to combat hate speech there could be dare consequences, especially in highly polarized societies that are always heated up along religious and ethnic sentiments. On daily basis tempers are flaring in the social media over comments made by participants. This study has also demonstrated that it is possible to implement a technology that can track and terminate hate speech in a micro-blog like Twitter. This can also be extended to other social media platforms.,This study will help to promote a more positive society, ensuring the social media is positively utilized to the benefit of mankind.,The findings can be used by social media companies to monitor user behaviors, and pin hate crimes to specific persons. Governments and law enforcement bodies can also use the POSA application to track down hate peddlers.",68518494,25,69,,SUTD - Roy Lee Task 1 Part 1
(missing DOI),"Computational Linguistics Against Hate: Hate Speech Detection and Visualization on Social Media in the ""Contro L'Odio"" Project","A. Capozzi, Mirko Lai, Valerio Basile, C. Musto, Marco Polignano, Fabio Poletto, M. Sanguinetti, C. Bosco, V. Patti, G. Ruffo, G. Semeraro, M. Stranisci",CLiC-it,2019,"The paper describes the Web platform built within the project “Contro l’odio”, for monitoring and contrasting discrimination and hate speech against immigrants in Italy. It applies a combination of computational linguistics techniques for hate speech detection and data visualization tools on data drawn from Twitter. It allows users to access a huge amount of information through interactive maps, also tuning their view, e.g., visualizing the most viral tweets and interactively reducing the inherent complexity of data. Educational courses for high school students and citizenship has been developed which are centered on the platform and focused on the deconstruction of negative stereotypes against immigrants, Roma, and religious minorities, and on the creation of positive narratives.",235445883,23,15,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1007/s10796-023-10446-x,Comparing Machine Learning and Deep Learning Techniques for Text Analytics: Detecting the Severity of Hate Comments Online,"Alaa Marshan, Farah Nasreen Mohamed Nizar, Athina Ioannou, Stella Despoudi",Information Systems Frontiers,2023,"Abstract Social media platforms have become an increasingly popular tool for individuals to share their thoughts and opinions with other people. However, very often people tend to misuse social media posting abusive comments. Abusive and harassing behaviours can have adverse effects on people's lives. This study takes a novel approach to combat harassment in online platforms by detecting the severity of abusive comments, that has not been investigated before. The study compares the performance of machine learning models such as Naïve Bayes, Random Forest, and Support Vector Machine, with deep learning models such as Convolutional Neural Network (CNN) and Bi-directional Long Short-Term Memory (Bi-LSTM). Moreover, in this work we investigate the effect of text pre-processing on the performance of the machine and deep learning models, the feature set for the abusive comments was made using unigrams and bigrams for the machine learning models and word embeddings for the deep learning models. The comparison of the models’ performances showed that the Random Forest with bigrams achieved the best overall performance with an accuracy of (0.94), a precision of (0.91), a recall of (0.94), and an F1 score of (0.92). The study develops an efficient model to detect severity of abusive language in online platforms, offering important implications both to theory and practice.",266381241,20,87,,SUTD - Roy Lee Task 1 Part 1
(missing DOI),Countering Online Hate Speech: An NLP Perspective,"Mudit Chaudhary, Chandni Saxena, Helen Meng",arXiv: Computation and Language,2021,"Online hate speech has caught everyone's attention from the news related to the COVID-19 pandemic, US elections, and worldwide protests. Online toxicity - an umbrella term for online hateful behavior, manifests itself in forms such as online hate speech. Hate speech is a deliberate attack directed towards an individual or a group motivated by the targeted entity's identity or opinions. The rising mass communication through social media further exacerbates the harmful consequences of online hate speech. While there has been significant research on hate-speech identification using Natural Language Processing (NLP), the work on utilizing NLP for prevention and intervention of online hate speech lacks relatively. This paper presents a holistic conceptual framework on hate-speech NLP countering methods along with a thorough survey on the current progress of NLP for countering online hate speech. It classifies the countering techniques based on their time of action, and identifies potential future research areas on this topic.",25780920,20,68,,SUTD - Roy Lee Task 1 Part 1
(missing DOI),Enhancing Multilingual Hate Speech Detection: From Language-Specific Insights to Cross-Linguistic Integration,"Ehtesham Hashmi, Sule Yildirim Yayilgan, Ibrahim A. Hameed, Muhammad Mudassar Yamin, Mohib Ullah, Mohamed Abomhara",IEEE Access,2024,(missing abstract),277272434,16,0,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
(missing DOI),Tools and Resources for Detecting Hate and Prejudice against Immigrants in Social Media,"C. Bosco, V. Patti, Marcello Bogetti, M. Conoscenti, G. Ruffo, R. Schifanella, M. Stranisci",(missing journal),2017,". This position paper describes the early stages of an on going project for the development of artiﬁcial intelligence tools and resourcestodetect andanalyzehatespeechandprejudiceagainst immigrants: IHATEPREJUDICE 3 . It istheresult of amulti-disciplinary team that includes skills from computational linguistics and sentiment analysis, to social network analysisand visualization. Theapproach followsaholistic and multi-lingual perspective, which encompassesdifferent knowledgesourcesto bemeaningfully aggregated. Thus, although the project is currently mainly focussed on a local case-study (Piedmont, a region of Italy), it is scalable over larger territories and different languages which can be considered as representative, namely the European Union. Since this is quite an innovative approach to the problem, this position paper aims at reaching out colleagues with a potential interest in this area and/or to solicitate feedback by those who are in the early stages of their projectsand wish to sharetheir experienceor join efforts.",153331946,15,17,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/access.2025.3532397,Hate Speech Detection using Large Language Models: A Comprehensive Review,"Aish Albladi, Minarul Islam, Amit Das, Maryam Bigonah, Zheng Zhang, Fatemeh Jamshidi, Mostafa Rahgouy, Nilanjana Raychawdhary, Daniela Marghitu, Cheryl Seals",IEEE Access,2025,(missing abstract),283381865,15,0,,SUTD - Roy Lee Task 1 Part 1
10.1007/s13278-024-01361-3,A comprehensive review on automatic hate speech detection in the age of the transformer,"Gil Ramos, Fernando Batista, Ricardo Ribeiro, Pedro Fialho, Sérgio Moro, António Fonseca, Rita Guerra, Paula Carvalho, Catarina Marques, Cláudia Silva",Social Network Analysis and Mining,2024,"The rapid proliferation of hate speech on social media poses significant challenges to maintaining a safe and inclusive digital environment. This paper presents a comprehensive review of automatic hate speech detection methods, with a particular focus on the evolution of approaches from traditional machine learning and deep learning models to the more advanced Transformer-based architectures. We systematically analyze over 100 studies, comparing the effectiveness, computational requirements, and applicability of various techniques, including Support Vector Machines, Long Short-Term Memory networks, Convolutional Neural Networks, and Transformer models like BERT and its multilingual variants. The review also explores the datasets, languages, and sources used for hate speech detection, noting the predominance of English-focused research while highlighting emerging efforts in low-resource languages and cross-lingual detection using multilingual Transformers. Additionally, we discuss the role of generative and multi-task learning models as promising avenues for future development. While Transformer-based models consistently achieve state-of-the-art performance, this review underscores the trade-offs between performance and computational cost, emphasizing the need for context-specific solutions. Key challenges such as algorithmic bias, data scarcity, and the need for more standardized benchmarks are also identified. This review provides crucial insights for advancing the field of hate speech detection and shaping future research directions.",279160818,14,122,,SUTD - Roy Lee Task 1 Part 2
10.1007/s43681-023-00281-w,Merging public health and automated approaches to address online hate speech,Tina Nguyen,AI and Ethics,2023,"The COVID-19 pandemic sparked a rise in misinformation from various media sources, which contributed to the heightened severity of hate speech. The upsurgence of hate speech online has devastatingly translated to real-life hate crimes, which saw an increase of 32% in 2020 in the United States alone (U.S. Department of Justice 2022). In this paper, I explore the current effects of hate speech and why hate speech should be widely recognized as a public health issue. I also discuss current artificial intelligence (AI) and machine learning (ML) strategies to mitigate hate speech along with the ethical concerns with using these technologies. Future considerations to improve AI/ML are also examined. Through analyzing these two contrasting methodologies (public health versus AI/ML), I argue that these two approaches applied by themselves are not efficient or sustainable. Therefore, I propose a third approach that combines both AI/ML and public health. With this proposed approach, the reactive side of AI/ML and the preventative nature of public health measures are united to develop an effective manner of addressing hate speech.",258069066,14,65,,SUTD - Roy Lee Task 1 Part 1
10.30935/ojcmt/13603,A comparative analysis of machine learning algorithms for hate speech detection in social media,"Esraa Omran, Estabraq Al Tararwah, Jamal Al Qundus",Online Journal of Communication and Media Technologies,2023,"A detecting and mitigating hate speech in social media, particularly on platforms like Twitter, is a crucial task with significant societal impact. This research study presents a comprehensive comparative analysis of machine learning algorithms for hate speech detection, with the primary goal of identifying an optimal algorithmic combination that is simple, easy to implement, efficient, and yields high detection performance. Through meticulous pre-processing and rigorous evaluation, the study explores various algorithms to determine their suitability for hate speech detection. The focus is finding a combination that balances simplicity, ease of implementation, computational efficiency, and strong performance metrics. The findings reveal that the combination of naïve Bayes and decision tree algorithms achieves a high accuracy of 0.887 and an F1-score of 0.885, demonstrating its effectiveness in hate speech detection. This research contributes to identifying a reliable algorithmic combination that meets the criteria of simplicity, ease of implementation, quick processing, and strong performance, providing valuable guidance for researchers and practitioners in hate speech detection in social media. By elucidating the strengths and limitations of various algorithmic combinations, this research enhances the understanding of hate speech detection. It paves the way for developing robust solutions, creating a safer, more inclusive digital environment.",267188180,12,14,,SUTD - Roy Lee Task 1 Part 1
10.1145/3711123,Decoding Fake News and Hate Speech: A Survey of Explainable AI Techniques,"Mikel K. Ngueajio, Saurav K. Aryal, M. Atemkeng, Gloria Washington, Danda B. Rawat",ACM Computing Surveys,2025,"This survey emphasizes the significance of Explainable AI (XAI) techniques in detecting hateful speech and misinformation/Fake news. It explores recent trends in detecting these phenomena, highlighting current research that reveals a synergistic relationship between them. Additionally, it presents recent trends in the use of XAI methods to mitigate the occurrences of hateful land Fake contents in conversations. The survey reviews state-of-the-art XAI approaches, algorithms, modeling datasets, as well as the evaluation metrics leveraged for assessing model interpretability, and thus provides a comprehensive summary table of the literature surveyed and relevant datasets. It concludes with an overview of key observations, offering insights into the prominent model explainability methods used in hate speech and misinformation detection. The research strengths, limitations are also presented, as well as perspectives and suggestions for future directions in this research domain.",283516191,11,111,,SUTD - Roy Lee Task 1 Part 1
10.48550/arxiv.2306.08804,PEACE: Cross-Platform Hate Speech Detection- A Causality-guided Framework,"Paras Sheth, Tharindu Kumarage, Raha Moraffah, Amanat Chadha, Huan Liu",ECML/PKDD,2023,"Hate speech detection refers to the task of detecting hateful content that aims at denigrating an individual or a group based on their religion, gender, sexual orientation, or other characteristics. Due to the different policies of the platforms, different groups of people express hate in different ways. Furthermore, due to the lack of labeled data in some platforms it becomes challenging to build hate speech detection models. To this end, we revisit if we can learn a generalizable hate speech detection model for the cross platform setting, where we train the model on the data from one (source) platform and generalize the model across multiple (target) platforms. Existing generalization models rely on linguistic cues or auxiliary information, making them biased towards certain tags or certain kinds of words (e.g., abusive words) on the source platform and thus not applicable to the target platforms. Inspired by social and psychological theories, we endeavor to explore if there exist inherent causal cues that can be leveraged to learn generalizable representations for detecting hate speech across these distribution shifts. To this end, we propose a causality-guided framework, PEACE, that identifies and leverages two intrinsic causal cues omnipresent in hateful content: the overall sentiment and the aggression in the text. We conduct extensive experiments across multiple platforms (representing the distribution shift) showing if causal cues can help cross-platform generalization.",262905359,11,44,,SUTD - Roy Lee Task 1 Part 1
10.48550/arxiv.2302.09618,Multilingual Content Moderation: A Case Study on Reddit,"Meng Ye, Karan Sikka, Katherine Atwell, Sabit Hassan, Ajay Divakaran, Malihe Alikhani",Conference of the European Chapter of the Association for Computational Linguistics,2023,"Content moderation is the process of flagging content based on pre-defined platform rules. There has been a growing need for AI moderators to safeguard users as well as protect the mental health of human moderators from traumatic content. While prior works have focused on identifying hateful/offensive language, they are not adequate for meeting the challenges of content moderation since 1) moderation decisions are based on violation of rules, which subsumes detection of offensive speech, and 2) such rules often differ across communities which entails an adaptive solution. We propose to study the challenges of content moderation by introducing a multilingual dataset of 1.8 Million Reddit comments spanning 56 subreddits in English, German, Spanish and French1. We perform extensive experimental analysis to highlight the underlying challenges and suggest related research problems such as cross-lingual transfer, learning under label noise (human biases), transfer of moderation models, and predicting the violated rule. Our dataset and analysis can help better prepare for the challenges and opportunities of auto moderation.",254258349,10,33,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.13052/rp-9788770220873,"Complex Project to Develop Real Tools for Identifying and Countering Terrorism: Real-time Early Detection and Alert System for Online Terrorist Content Based on Natural Language Processing, Social Network Analysis, Artificial Intelligence and Complex Event Processing","M. Florea, Cristi Potlog, P. Pollner, D. Abel, O. Garcia, S. Bar, Syed Naqvi, Waqar Asif",(missing journal),2019,"In the last decades, the importance of social media has increased extremely with the creation of new communication channels and even changing the way people are communicating. These trends came along with the disadvantage of allowing a new scenario where messages containing valuable data about critical threats like terrorism and criminal activity are ignored, due to the sheer inability to process – much less analyze – the vast amount of available data. Terrorism has a very real and direct impact on basic human rights of victims, such as the right to life, liberty and physical integrity, often with devastating consequences. 
 
In this context, the RED-Alert project was designed to build a complete software toolkit to support LEAs in the fight against the use of social media by terrorist organizations for conducting online propaganda, fundraising, recruitment and mobilization of members, planning and coordination of actions, as well as data manipulation and misinformation. The project aims to cover a wide range of social media channels used by terrorist groups to disseminate their content which will be analysed by the RED-Alert solution to support LEAs to take coordinated action in real time but having as a primordial condition preserving the privacy of citizens.",138831995,10,0,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.2478/jsiot-2023-0020,ML and Natural Language Processing : Cyberbullying Detection System for Safer and Culturally Adaptive Digital Communities,"Viraj Shah, Anurag Sinha, Nilesh Navalkar, Shubham Gupta, Priyanca Gonsalves, Akshit Malik",Journal of Smart Internet of Things,2023,"Abstract Cyberbullying has become a ubiquitous menace in our digitally connected society, requiring strong detection and classification systems. This study presents a multi-tiered system that reliably detects and classifies instances of cyberbullying on a variety of platforms by utilising cutting-edge machine learning and natural language processing approaches. Our algorithm, which was trained on a wide range of datasets, shows excellent accuracy in differentiating between instances of cyberbullying and non-bullying situations while taking linguistic and cultural quirks into account. Furthermore, our flexible system guarantees applicability by adjusting to changing cyberbullying patterns. By promoting safer and more inclusive digital communities, our research helps to design proactive treatments that lessen the effects of online harassment. This study introduces a robust multi-tiered system designed for the detection and classification of cyberbullying across diverse digital platforms. Leveraging state-of-the-art machine learning and natural language processing techniques, our algorithm, trained on extensive datasets, exhibits exceptional accuracy in distinguishing cyberbullying instances from non-bullying scenarios while accommodating linguistic and cultural nuances. The system’s adaptability to evolving cyberbullying patterns ensures continued efficacy. By fostering safer and more inclusive online environments, our research contributes to proactive measures and mitigates the impact of digital harassment.",268820148,8,8,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1016/j.heliyon.2023.e16084,A web framework for information aggregation and management of multilingual hate speech.,"Rigas Kotsakis, Lazaros Vrysis, Nikolaos Vryzas, Theodora Saridou, Maria Matsiola, Andreas Veglis, Charalampos Dimoulas",Heliyon,2023,(missing abstract),262635002,8,14,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/icsmdi57622.2023.00028,Enhancing Hate Speech Detection through Explainable AI,"Dipti Mittal, Harmeet Singh",2023 3rd International Conference on Smart Data Intelligence (ICSMDI),2023,"The potential of XAI in detecting hate speech using deep learning models is versatile and multifaceted. To better understand the decision-making process of complex AI models, this study applied XAI to the dataset and investigated the interpretability and explanation of their decisions. The data was preprocessed by cleaning, tokenizing, lemmatizing, and removing inconsistencies in tweets. Simplification of categorical variables was also performed during training. Exploratory data analysis was conducted to identify patterns and insights in the dataset. The study used a set of existing models, including LIME, SHAP, XGBoost, and KTrain, to analyze the accuracy. The KTrain model achieved the highest accuracy and lowest loss among the variants developed to increase explainability.",261922623,7,22,,SUTD - Roy Lee Task 1 Part 1
10.1109/access.2024.3444188,Hate Speech and Target Community Detection in Nastaliq Urdu Using Transfer Learning Techniques,"Muhammad Shahid Iqbal Malik, Aftab Nawaz, Mona Jamjoom",IEEE Access,2024,(missing abstract),275834360,7,0,,SUTD - Roy Lee Task 1 Part 1
10.1109/access.2024.3470901,Fine-grained multilingual Hate speech detection using Explainable AI and Transformers,"Jawaid Ahmed Siddiqui, Siti Sophiayati Yuhaniz, Ghulam Mujtaba, Safdar Ali Soomro, Zafar Ali Mahar",IEEE Access,2024,(missing abstract),278208558,7,0,,SUTD - Roy Lee Task 1 Part 1
10.1007/s13369-024-09540-2,Improving Hate Speech Classification Through Ensemble Learning and Explainable AI Techniques,"Priya Garg, Meenakshi Sharma, Parteek Kumar",Arabian Journal for Science and Engineering,2024,(missing abstract),279960418,6,52,,SUTD - Roy Lee Task 1 Part 1
10.1145/3240431.3240437,"A Data Viz Platform as a Support to Study, Analyze and Understand the Hate Speech Phenomenon","A. Capozzi, V. Patti, G. Ruffo, C. Bosco",Proceedings of the 2nd International Conference on Web Studies,2018,"In this paper we present a data visualization platform designed to support the Natural Language Processing (NLP) scholar to study and analyze different corpora collected with the purpose to understand the hate speech phenomenon in social media. The project started with the creation of a corpus which collects tweets addressed to specific groups of ethnic minorities considered very controversial in the Italian public debate. Each tweet has been manually tagged with a series of attributes in order to capture the different features used to characterize the hate speech phenomenon. This corpus is mainly built to be used for training an automatic classifier and helping us in its testing and validation, before being it adopted to detect tweets targeted as hate speech on larger scale datasets. As opposed as many other traditional machine learning tasks, to build a good classifier achieving high scores in terms of accuracy is very challenging in such scenario, because of the intrinsic ambiguity of the language, the lack of a proper and explicable context in social media, and the attitude of on line users of being sarcastic and ironical. Therefore, in order to properly validate an effective feature selection process, correlations between selected attributes must be studied and analyzed. This motivated us to build an interactive platform to explore data in our corpora across the dimensions that have been used to characterize collected tweets. In our paper, after a brief introduction of the hate speech dataset, we will show how the dashboard can fit into the NLP pipeline, and how its architecture can be structured. Finally, we will present some of the challenges we have faced to visualize data with spatial, temporal and numerical attributes.",184140010,5,19,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/ntms.2019.8763830,Privacy-Preserving Social Media Forensic Analysis for Preventive Policing of Online Activities,"Syed Naqvi, Sean Enderby, Ian Williams, Waqar Asif, M. Rajarajan, Cristi Potlog, M. Florea","2019 10th IFIP International Conference on New Technologies, Mobility and Security (NTMS)",2019,"Social media is extensively used nowadays and is gaining popularity among the users with the increasing growth in the network capacity, connectivity, and speed. Moreover, affordable prices of data plans, especially mobile data packages, have considerably increased the use of multimedia by different users. This includes terrorists who use social media platforms to promote their ideology and intimidate their adversaries. It is therefore very important to develop automated solutions to semantically analyse given multimedia contents to assist law enforcement agencies in the preventive policing of online activities. A major challenge for the social media forensic analysis is to preserve the privacy of citizens who use online social networking platforms. This paper presents results of European H2020 project RED-Alert that aims to enable secure and privacy preserving data processing; hence the malicious content and the corresponding personality can be tracked while the privacy of innocent citizens can be preserved. We have mined seven social media channels for content and providing support for ten languages for analysis. Our proposed solution is designed to ensure security and policing of online contents by detecting terrorist material. We have used speech recognition, face and object detection besides audio event detection to extract information from multimedia files. We have applied anonymization techniques to ensure the privacy of citizens using social media. We have discussed the challenges and prospects of this work especially the need of using digital forensic techniques while respecting European and national data protection laws notably GDPR.",110527616,5,3,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1002/widm.70029,A Literature Review of Textual Cyber Abuse Detection Using Cutting-Edge Natural Language Processing Techniques: Language Models and Large Language Models,"J. A. Diaz-Garcia, Joao Paulo Carvalho",WIREs Data Mining and Knowledge Discovery,2025,"The success of social media platforms has facilitated the emergence of various forms of online abuse within digital communities. This abuse manifests in multiple ways, including hate speech, cyberbullying, emotional abuse, grooming, and shame sexting or sextortion. In this paper, we present a comprehensive analysis of the different forms of abuse prevalent in social media, with a particular focus on how emerging technologies, such as Language Models (LMs) and Large Language Models (LLMs), are reshaping both the detection and generation of abusive content within these networks. We delve into the mechanisms through which social media abuse is perpetuated, exploring the psychological and social impact. To achieve this, we conducted a literature review based on PRISMA methodology, deriving key insights in the field of cyber abuse detection. Additionally, we examine the dual role of advanced language models—highlighting their potential to enhance automated detection systems for abusive behavior while also acknowledging their capacity to generate harmful content. This paper contributes to the ongoing discourse on online safety and ethics by offering both theoretical and practical insights into the evolving landscape of cyber abuse, as well as the technological innovations that simultaneously mitigate and exacerbate it. The findings support platform administrators and policymakers in developing more effective moderation strategies, conducting comprehensive risk assessments, and integrating AI responsibly to create safer digital environments.This article is categorized under:

Algorithmic Development > Web Mining
Technologies > Classification
",288271789,4,203,,SUTD - Roy Lee Task 1 Part 1
(missing DOI),Hate Speech Detection using LIME guided Ensemble Method and DistilBERT,"N. Deepakindresh, Rohan Avireddy, Aakash Ambalavanan, B. Selvamani",FIRE,2021,"Hate Speech classification has crucial applications in the social media domain. We describe the performance of our classifiers in the Hate Speech and Offensive Content Identification Track (HASOC) of FIRE 2021 conference. The dataset provided is for Indo-European Languages. We chose English tweets and developed two main classifiers as part of HASOC Track 1, which had two Subtasks 1A and 1B. Subtask 1A is a binary Hate Speech identification task, and Subtask 1B is multi grained classification of hate, profane, offensive and neutral content. Our team ”Beware Haters” studied Support Vector Machine, Random Forest, Logistic Regression, Bidirectional Long Short Term Memory Model and an Ensemble of the listed models for the Subtask 1A and the highest Macro F1 score we achieved was 0.7722 by our Ensemble model which combined the advantages of SVM, Logistic Regression and Random Forest. We used a model interpretation tool LIME, before integrating the models in a weighted Ensemble approach. For Subtask 1B, we obtained better results using a DistilBERT model that achieved a Macro F1 score of 0.6311. We have compared the performance of the basic DistilBERT Model with a fine tuned version.",243782459,4,14,,SUTD - Roy Lee Task 1 Part 1
10.54501/jots.v2i1.150,Toward Better Automated Content Moderation in Low-Resource Languages,"Gabriel Nicholas, Aliya Bhatia",Journal of Online Trust and Safety,2023,"Social media companies have learned the hard way that poor moderation of content in languages other than English can have grave consequences. Leaving harmful content up, particularly in regions where social media platforms are primary news and communication channels, has fueled conspiracy theories, violence, and even genocide around the world (Fink 2018; Iyengar 2018). American social media companies have long faced criticism for underinvesting in regions outside the US and Europe. In response, Meta, Google, and others have begun to deploy newmultilingual language models that they claim can effectively detect and take action on harmful content in dozens if not hundreds of languages (Jigsaw 2021; Meta AI 2021b).",265194241,4,23,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
(missing DOI),Large-Scale Hate Speech Detection with Cross-Domain Transfer,"Toraman, Cagri, Şahinuç, Furkan, Yılmaz, Eyup Halit",(missing journal),2022,"The performance of hate speech detection models relies on the datasets on which the models are trained. Existing datasets are mostly prepared with a limited number of instances or hate domains that define hate topics. This hinders large-scale analysis and transfer learning with respect to hate domains. In this study, we construct large-scale tweet datasets for hate speech detection in English and a low-resource language, Turkish, consisting of human-labeled 100k tweets per each. Our datasets are designed to have equal number of tweets distributed over five domains. The experimental results supported by statistical tests show that Transformer-based language models outperform conventional bag-of-words and neural models by at least 5% in English and 10% in Turkish for large-scale hate speech detection. The performance is also scalable to different training sizes, such that 98% of performance in English, and 97% in Turkish, are recovered when 20% of training instances are used. We further examine the generalization ability of cross-domain transfer among hate domains. We show that 96% of the performance of a target domain in average is recovered by other domains for English, and 92% for Turkish. Gender and religion are more successful to generalize to other domains, while sports fail most.",83202852,3,0,,SUTD - Roy Lee Task 1 Part 1
10.1109/csci54926.2021.00180,A new SOCMINT framework for Threat Intelligence Identification,"Marco San Biagio, R. Acquaviva, Valentina Mazzonello, Ernesto La Mattina, V. Morreale",2021 International Conference on Computational Science and Computational Intelligence (CSCI),2021,"Social Media platforms have changed the way of communication between people. These platforms allow users and organizations to communicate with each other, sharing their ideas, interests, and knowledge, becoming a part of their daily routine. On the other hand, social media platforms represent good channels to exploit for perpetrating various kinds of crimes and crimes illegal activities in several criminal areas, including cyber-crimes and terrorism. The goal of this work is to present a novel framework for Threat Intelligence that adopts Machine Learning and Artificial Intelligence techniques for OSINT (Open–source intelligence) investigation can extract actionable intelligence for threats.",230543813,3,22,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.5121/csit.2022.121516,A Transformer based Multi-Task Learning Approach Leveraging Translated and Transliterated Data to Hate Speech Detection in Hindi,"Prashant Kapil, Asif Ekbal",Data Science and Machine Learning,2022,"The increase in usage of the internet has also led to an increase in unsocial activities, hate speech is one of them. The increase in Hate speech over a few years has been one of the biggest problems and automated techniques need to be developed to detect it. This paper aims to use the eight publicly available Hindi datasets and explore different deep neural network techniques to detect aggression, hate, abuse, etc. We experimented on multilingual-bidirectional encoder representations from the transformer (M-BERT) and multilingual representations for Indian languages (MuRIL) in four settings (i) Single task learning (STL) framework. (ii) Transfering the encoder knowledge to the recurrent neural network (RNN). (iii) Multi-task learning (MTL) where eight Hindi datasets were jointly trained and (iv) pre-training the encoder with translated English tweets to Devanagari script and the same Devanagari scripts transliterated to romanized Hindi tweets and then fine-tuning it in MTL fashion. Experimental evaluation shows that cross-lingual information in MTL helps in improving the performance of all the datasets by a significant margin, hence outperforming the state-of-the-art approaches in terms of weightedF1 score. Qualitative and quantitative error analysis is also done to show the effects of the proposed approach.",249886906,3,53,,SUTD - Roy Lee Task 1 Part 1
10.5220/0013070000003825,Hate Speech Detection Using Cross-Platform Social Media Data in English and German Language,"Gautam Kishore Shahi, Tim A. Majchrzak",(missing journal),2024,(missing abstract),281531123,3,0,,SUTD - Roy Lee Task 1 Part 1
(missing DOI),Exploring Intensities of Hate Speech on Social Media: A Case Study on Explaining Multilingual Models with XAI,"Raisa Romanov Geleta, Klaus Eckelt, Emilia Parada-Cabaleiro, Markus Schedl","International Conference on Language, Data, and Knowledge",2023,(missing abstract),271163311,2,0,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/eurospw.2019.00035,Towards Fully Integrated Real-time Detection Framework for Online Contents Analysis - RED-Alert Approach,"Syed Naqvi, Ian Williams, Sean Enderby, Péter Pollner, Daniel Abel, Berta Biescas, Oscar Garcia, Monica Florea, Cristi Potlog",(missing journal),2019,"Social media is extensively used nowadays and is gaining popularity among the users with the increasing growth in the network capacity, connectivity, and speed. Moreover, affordable prices of data plans, especially mobile data packages, have considerably increased the use of multimedia by different users. This includes terrorists who use social media platforms to promote their ideology and intimidate their adversaries. It is therefore very important to develop automated solutions to semantically analyse online contents to assist law enforcement agencies in the preventive policing of online activities. A major challenge for the social media forensic analysis is to preserve the privacy of citizens who use online social networking platforms. This paper presents results of European H2020 project RED-Alert that aims to enable secure and privacy preserving data processing; hence the malicious content and the corresponding personality can be ethically tracked. We have mined seven social media channels for content and providing support for ten languages for analysis. Our proposed solution is designed to ensure security and policing of online contents by detecting terrorist material. We have used social network analysis, speech recognition, face and object detection besides audio event detection to extract information from online sources that are fed in a complex event processor. We have discussed the challenges and prospects of this work especially the need of analysing online contents while respecting European and national data protection laws notably GDPR.",188317005,2,8,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/acdsa59508.2024.10467738,MARPLE: A Framework for Social Media Threat Intelligence,"Marco San Biagio, Simone Simoncini, Ernesto La Mattina, V. Morreale","2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)",2024,"In last years, the use of social media platforms by terrorist organizations have become more evident. Since the emergence of digital communication, extremist groups have had unheard-of possibilities to spread their beliefs, enlist new members, and plan pervasive radicalization campaigns. Terrorist organizations utilize social media to span their messages, taking advantage of its wide audience, anonymity, and instantaneous connectivity. For this reason, Social Media Intelligence (SOCMINT) is becoming an effective mean to support LEAs in monitoring of social media, blogs, and forums to identify any suspicious content and potential terrorist threat. The goal of this work is to propose an AI-based Threat Intelligence tool that applies Deep Learning techniques for OSINT (Open-Source Intelligence) investigation, supporting intelligence analysts and investigators to timely identify terrorist threats from social networks. Results obtained on a newly created dataset confirm the efficiency and effectiveness of the proposed tool in the identification of malicious posts related to terrorist activities.",270704370,2,30,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.48084/etasr.13249,Cross-Platform Hate Speech Detection Using an Attention-Enhanced BiLSTM Model,"Muzammil Hussain, Waqas Sharif, M. Faheem, Yazeed Alsarhan, Hany A. Elsalamony","Engineering, Technology &amp; Applied Science Research",2025,"Hate speech is rapidly spreading across digital platforms, appearing in diverse forms driven by regional, cultural, and linguistic differences. This growing trend presents serious challenges to social harmony and online safety. Existing hate speech detection models often fall short because they rely on limited and homogeneous datasets, making them less effective in real-world, culturally diverse settings. Handling large-scale, diverse datasets adds notable complexity to capturing contextual nuances, as different populations and cultures demonstrate unique language patterns and expressions. This study addresses the necessity for a more universal solution by proposing a deep learning model trained on an extensive and diverse dataset comprising 842,000 samples collected from various digital platforms. The approach combines a Bidirectional Long Short-Term Memory (BiLSTM) model with a self-attention mechanism to capture contextual depth. Various data embedding techniques were used to assess their impact, along with data resampling and standard Natural Language Processing (NLP) pre-processing steps. The proposed model achieved 93% accuracy with an F1-score of 0.92, outperforming several baseline and state-of-the-art models. This work provides a comprehensive and scalable framework for the detection of hate speech across various online platforms.",297799049,2,41,,SUTD - Roy Lee Task 1 Part 1
10.3390/computers14070279,A Large Language Model-Based Approach for Multilingual Hate Speech Detection on Social Media,"Muhammad Usman, Muhammad Ahmad, Grigori Sidorov, Irina Gelbukh, Rolando Quintero",Computers,2025,"The proliferation of hate speech on social media platforms poses significant threats to digital safety, social cohesion, and freedom of expression. Detecting such content—especially across diverse languages—remains a challenging task due to linguistic complexity, cultural context, and resource limitations. To address these challenges, this study introduces a comprehensive approach for multilingual hate speech detection. To facilitate robust hate speech detection across diverse languages, this study makes several key contributions. First, we created a novel trilingual hate speech dataset consisting of 10,193 manually annotated tweets in English, Spanish, and Urdu. Second, we applied two innovative techniques—joint multilingual and translation-based approaches—for cross-lingual hate speech detection that have not been previously explored for these languages. Third, we developed detailed hate speech annotation guidelines tailored specifically to all three languages to ensure consistent and high-quality labeling. Finally, we conducted 41 experiments employing machine learning models with TF–IDF features, deep learning models utilizing FastText and GloVe embeddings, and transformer-based models leveraging advanced contextual embeddings to comprehensively evaluate our approach. Additionally, we employed a large language model with advanced contextual embeddings to identify the best solution for the hate speech detection task. The experimental results showed that our GPT-3.5-turbo model significantly outperforms strong baselines, achieving up to an 8% improvement over XLM-R in Urdu hate speech detection and an average gain of 4% across all three languages. This research not only contributes a high-quality multilingual dataset but also offers a scalable and inclusive framework for hate speech detection in underrepresented languages.",288840772,2,30,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.5282/ubm/epub.76087,"Artificial Intelligence, Extreme Speech and the Challenges of Online Content Moderation","Sahana Udupa, Elonnai Hickok, Antonis Maronikolakis, Hinrich Schuetze, Laura Csuka, Axel Wisiorek, Leah Nann",(missing journal),2021,(missing abstract),261362217,2,0,,SUTD - Roy Lee Task 1 Part 1
10.1109/inocon60754.2024.10511522,Understanding the Evolution of Abusive Behaviour in Online Social Networks,"Ovais Bashir Gashroo, Monica Mehrotra",2024 3rd International Conference for Innovation in Technology (INOCON),2024,"This paper presents a comprehensive investigation into the intricate dynamics of abusive behaviour in online social networks, utilizing cutting-edge methodologies at the intersection of computer science, natural language processing (NLP), and social network analysis. Cross-platform and cultural variances are rigorously examined, addressing challenges posed by platform-specific features and linguistic nuances. Innovative approaches including transfer learning, adversarial training, and multimodal analysis showcase the adaptability of models to diverse online environments. The technical depth of the paper is evident in the exploration of NLP advancements, leveraging state-of-the-art models such as BERT and GPT-3 for a nuanced understanding of abusive language. Machine learning models, including ensemble approaches and deep learning architectures like CNNs and RNNs, are harnessed for precise classification tasks. Social network analysis metrics uncover patterns of influence and community dynamics contributing to abusive behaviour. The research navigates ethical considerations with finesse, addressing issues of privacy, algorithmic fairness, and bias mitigation. The cross-cultural and cross-platform analyses are underpinned by carefully curated datasets that encapsulate the diverse nature of online interactions, ensuring the robustness and generalizability of the proposed methodologies. In conclusion, this paper not only contributes to the evolving landscape of abusive behaviour research but also establishes a benchmark for interdisciplinary studies. The technical acumen demonstrated in the methodologies, coupled with a commitment to ethical practices, positions this research at the forefront of endeavours to comprehend, predict, and mitigate abusive behaviour in the dynamic realm of online social networks.",272053700,1,34,,SUTD - Roy Lee Task 1 Part 1
10.1117/12.2306712,The event tracking dashboard: from multilingual social media feeds to event patterns and anomalies,"P. Giridhar, Jongdeog Lee, T. Abdelzaher, Lance M. Kaplan",Defense + Security,2018,"The proliferation of real-time information on social media opens up unprecedented opportunities for situation awareness that arise from extracting unfolding physical events from their social media footprints. The paper describes experiences with a new social media analysis toolkit for detecting and tracking such physical events. A key advantage of the explored analysis algorithms is that they require no prior training, and as such can operate out-of-the-box on new languages, dialects, jargon, and application domains (where by ""new"", we mean new to the machine), including detection of protests, natural disasters, acts of terror, accidents, and other disruptions. By running the toolkit over a period of time, patterns and anomalies are also detected that offer additional insights and understanding. Through analysis of contemporary political, military, and natural disaster events, the work explores the limits of the training-free approach and demonstrates promise and applicability.",211032537,1,6,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/delcon64804.2024.10867230,Proposed Framework for Detecting Multilingual Hate Speech on Social Media Platform,"Rachna Narula, Poonam Chaudhary",2024 3rd Edition of IEEE Delhi Section Flagship Conference (DELCON),2024,"This research introduces a smart system that can find hurtful words in many different languages on the internet. It uses special computer programs that help it understand how different languages work, so it can spot hate speech correctly. These programs, like BERT and GPT, help the system learn and improve. The way the system is built allows it to quickly work in real-time, which means it can help keep online spaces safe and friendly while easily adding new languages or adjusting to new ways people talk online. This system is really helpful for keeping social media nice and supportive by checking for bad words in posts, like those on Twitter, and training to get better at it.",284128561,0,20,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/aespc63931.2024.10872383,Real-Time Hate Speech Recognition Along with Educational Feedback and Automatic Reporting,"Abhilasha Panda, Abhijeet Anand, Sujit Bebortta, Subhranshu Sekhar Tripathy, Tanmay Mukherjee","2024 IEEE 4th International Conference on Applied Electromagnetics, Signal Processing, & Communication (AESPC)",2024,"In today's digital era, the rise of toxicity, discrimination, and harm on online communication platforms has become a significant concern, necessitating effective moderation strategies. Existing methods for hate speech detection often lack real-time capabilities and fail to provide constructive feedback to users. Natural Language Processing (NLP) is used to identify the intent of the speech and bidirectional Long Short Term Memory (LSTM) machine learning algorithm classifies text into multiple hate speech categories. The designed system also displays charts, providing a detailed assessment and understanding of the nature and severity of the content. With a user-friendly interface, users receive real-time educational feedback on the nature and impact of different types of hate speech, promoting awareness and discouraging toxic behavior.",284101455,0,11,,SUTD - Roy Lee Task 1 Part 1
10.3390/electronics15020442,Cross-Platform Multi-Modal Transfer Learning Framework for Cyberbullying Detection,"Weiqi Zhang, Chengzu Dong, Aiting Yao, A. Nazari, Anuroop Gaddam",Electronics,2026,"Cyberbullying and hate speech increasingly appear in multi-modal social media posts, where images and text are combined in diverse and fast changing ways across platforms. These posts differ in style, vocabulary and layout, and labeled data are sparse and noisy, which makes it difficult to train detectors that are both reliable and deployable under tight computational budgets. Many high performing systems rely on large vision language backbones, full parameter fine tuning, online retrieval or model ensembles, which raises training and inference costs. We present a parameter efficient cross-platform multi-modal transfer learning framework for cyberbullying and hateful content detection. Our framework has three components. First, we perform domain adaptive pretraining of a compact ViLT backbone on in domain image-text corpora. Second, we apply parameter efficient fine tuning that updates only bias terms, a small subset of LayerNorm parameters and the classification head, leaving the inference computation graph unchanged. Third, we use noise aware knowledge distillation from a stronger teacher built from pretrained text and CLIP based image-text encoders, where only high confidence, temperature scaled predictions are used as soft labels during training, and teacher models and any retrieval components are used only offline. We evaluate primarily on Hateful Memes and use IMDB as an auxiliary text only benchmark to show that the deployment aware PEFT + offline-KD recipe can still be applied when other modalities are unavailable. On Hateful Memes, our student updates only 0.11% of parameters and retain about 96% of the AUROC of full fine-tuning.",298403405,0,16,,SUTD - Roy Lee Task 1 Part 1
10.1145/3748492,Advancements in Transformer-Based Models for Enhanced Hate Speech Detection in Arabic: Addressing Dialectal Variations and Cross-Platform Challenges,"Ahmed Fat’hAlalim, Yongjian Liu, Qing Xie, Nahla Ibrahim",ACM Transactions on Asian and Low-Resource Language Information Processing,2025,"The rise of social media platforms has greatly amplified the spread of hate speech, which poses serious societal risks. The automated detection of hate speech on social media, especially in low-resource Arabic language, presents unique challenges owing to linguistic diversity, dialectal differences, and regional nuances. However, most current research efforts primarily focus on a single social media platform, which hinders the ability to address dialect differences, as residents of Arab regions often favor one platform over another. This study provides an in-depth analysis of Arabic hate speech detection using advanced transformer-based models across three datasets collected from diverse social media platforms. Our models include multilingual, monolingual models pretrained in Arabic, and models that employ transfer learning from rich-resource English. To provide a thorough evaluation, we also compared the performance of our transformer-based models with two baseline models: LR and NBSVM, highlighting their relative effectiveness in detecting hate speech across multi-dialect and multi-platforms. Our analysis includes the effects of oversampling, data augmentation, and model interpretability using the LIME method. The monolingual transformer-based models, in particular, demonstrated significant performance improvements, setting new benchmarks for F1-scores and surpassing traditional models, our best classifier achieved an F1-score of 98.82%. Additionally, we conducted thorough cross-validation across datasets to evaluate the models’ generalization capabilities. Our research significantly advances Arabic hate speech detection by tackling these complexities and laying a solid foundation for future research. However, challenges remain in detecting subtle forms of hate speech, such as implicit hate speech and fine-grained distinctions between offensive content.",288944040,0,59,,SUTD - Roy Lee Task 1 Part 1
10.1109/ubmk67458.2025.11207036,Review of Multilingual Social Media Hate Speech Identification and Mitigation,"A. Zhidebayeva, Gulnar Madaliyeva, N.F. Sarsenbiyeva, Toktarova Aigerim, Zhanar Kemelbekova, Bayan Tastanbekova",2025 10th International Conference on Computer Science and Engineering (UBMK),2025,"This work focuses on the proliferation of hate speech among children and adolescents, emphasizing the creation of a particular methodological framework to combat this issue within the Kazakhstani section of social networks. The study incorporates findings from international research undertaken in the USA, Great Britain, and various European nations, employing a complete methodology that encompasses theoretical analysis, synthesis, empirical comparison, and aspects of experimental techniques. Special emphasis is placed on the application of technical solutions for the identification and prevention of hate speech. The research investigates the development of a parser and the methodical accumulation of data required for training machine and deep learning algorithms to detect offensive and toxic remarks in real time. The developed solutions are designed to enhance the efficiency of automatic moderation on online platforms and safeguard vulnerable user groups. The study targets both novices and seasoned professionals in data analysis, highlighting the necessity for enhanced practical research in the utilization of deep learning algorithms. Future plans include the development of the proposed methodologies and the publication of articles focused on a comprehensive examination and optimization of intellectual models to combat the proliferation of hate speech.",291912991,0,18,,"SUTD - Roy Lee Task 1 Part 2, SUTD - Roy Lee Task 1 Part 3"
10.1109/icimia67127.2025.11200817,Cross-Platform Hate Speech Propagation Analysis using Machine Learning,"K. R, Megalan A, Selvarathinam S, Pragadheesh P",International Conference on Innovative Mechanisms for Industry Applications,2025,"The study begins by web scraping diverse datasets from various social platforms. The collected text data consists of posts, comments, and threads from engaged and polarized discussion platforms. Social media text is loud and unstructured, and several preprocessing techniques are used to clean and normalize it. The preprocessing method is based on the Term Frequency-Inverse Document Frequency (TF-IDF). Recursive Feature Elimination (RFE) is used, gradually reducing the feature set to the most crucial ones for identifying hate speech by iteratively training a model. The classification phase utilizes Bidirectional Long-Short Term Memory (BiLSTM) networks to detect hate speech in text by capturing contextual dependencies in both forward and backward directions. The model's performance was assessed using conventional classification metrics, including accuracy (94.1%). Platform-specific metrics are also computed to analyze differences in linguistic structures and user behavior on social platforms. Cross-validation and stratified sampling are employed to ensure a balanced assessment across various subsets of data.",292213520,0,17,,SUTD - Roy Lee Task 1 Part 1
10.1109/access.2025.3629527,MUST: An explainable AI–based framework for MUltilingual hate Speech deTection,"Ijaz Hussain, Muhammad Afzal Rizvi, Zain Abbas, Ammara Nawaz Cheema, Ibrahim M. Almanjahie",IEEE Access,2025,(missing abstract),292802279,0,0,,SUTD - Roy Lee Task 1 Part 1
10.1109/icscan58655.2023.10395354,Ensemble Text Classification with TF-IDF Vectorization for Hate Speech Detection in Social Media,"S. R, Karthikeyan T, Praveen kumar P, Shamsundar S M","2023 International Conference on System, Computation, Automation and Networking (ICSCAN)",2023,"The development of artificial intelligence (AI) has changed how hate speech is detected. In hate speech identification using machine learning, a number of methods are used to automatically find text that uses vocabulary that is considered to be derogatory, discriminatory, or motivated by hatred. Supervised learning techniques like neural networks, decision trees, and SVMs need a labelled dataset comprising samples of hate speech and non-hate speech. This project investigates the use of AI and machine learning techniques to automatically detect material that uses offensive, intolerant, or hostile words. A voting classifier and TF-IDF representations are combined to improve classification accuracy. The ensemble of classifiers, powered by AI approaches, shows impressive accuracy in identifying hate speech by training five different classifiers (Random Forest, Bagging, Support Vector Machine, AdaBoost, and Gradient Boosting) on a labelled dataset of tweets. The TF-IDF representation prioritises textual terms, whereas the ensemble method uses classifier diversity to capture distinctive patterns. Results from experiments show the strategy's effectiveness, with precision 0.95, recall 0.96, f1-score 0.95 and accuracy 0.97 for detecting hate speech. By successfully utilising AI's capacity to fight hate speech, this research helps the development of a diverse and secure online environment. The suggested approach works well for automatically identifying hate speech, making the internet a safer and more welcoming place for all users.",268830318,0,21,,SUTD - Roy Lee Task 1 Part 1
10.1109/i-pact65952.2025.11308070,Leveraging AI for Real-Time Detection and Intervention in Online Harassment,"Bhavya Balakrishnan, G. G, Lakshay S, Krupa N, Niranjan C B",2025 Innovations in Power and Advanced Computing Technologies (i-PACT),2025,"Across numerous social media apps and other online platforms, cyberbullying and online harassment have become rampant. The intricacy of language in detecting indirect bullying, coded hate speech, sarcasm, and enormous volumes of data are too much for the current systems to handle. This paper mainly deals with Natural Language Processing (NLP) and AI to develop and automated system to detect and prevent online harassment's in real time. Using RoBERTa for subtle harassment detection and DistilBERT for quick real-time filtering, the system can reliably detect explicit hate speech, subtle harassment, and conversational toxicity. creating a fine-tuned model using a custom Jigsaw dataset and integrating it with web applications based on MERN, Redis caching to improve speed, WebSockets to monitor chats in real time, and explainable AI tools like SHAP/LIME to provide immediate moderation actions like alerting users, flagging content for review, and automatically removing abusive messages.",297821086,0,5,,SUTD - Roy Lee Task 1 Part 1
10.1109/tqcebt59414.2024.10545188,Advanced Approaches for Hate Speech Detection: A Machine and Deep Learning Investigation,"Arun Reghunathan, Saummya Singh, G. R., Amala Johnson",2024 International Conference on Trends in Quantum Computing and Emerging Business Technologies,2024,"The prevalence of online social media platforms has led to an alarming rise in the frequency of cyberbullying and hate speech. This study uses a variety of machine-learning approaches and deep- learning algorithms to identify hate speech. The goal is to create a thorough and successful method for locating and categorizing hate speech on online networks. Our suggested approach intends to deliver a comprehensive solution to address the urgent problem of cyberbullying and hate speech in the digital sphere by leveraging the strength of these cutting-edge techniques. We work to make social media users' online experiences safer and more welcoming by identifying and addressing such harmful online actions. Through rigorous experimentation, we evaluate the efficacy of these methodologies, ultimately revealing that the Bidirectional Gated Recurrent Unit (Bi-GRU) outperforms the other employed techniques. The Bi-GRU model demonstrates superior hate speech detection capabilities, substantiated by robust performance metrics. This research contributes to the field by providing empirical evidence that deep learning models, such as Bi-GRU, can significantly advance hate speech detection accuracy. The findings underscore the potential of leveraging advanced neural architectures in the pursuit of fostering a more inclusive and respectful digital space.",277185390,0,14,,SUTD - Roy Lee Task 1 Part 1
